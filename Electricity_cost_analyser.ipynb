{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyORTQaiQrMYe7ul0f0AHRDJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshxx2/Electricity_cost-analyser/blob/main/Electricity_cost_analyser.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "mNqdJ-FYZH2v",
        "outputId": "5f3899b4-c026-422e-de2f-bda4377f40ca"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'electricity_cost_dataset.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1210263018.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Load dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"electricity_cost_dataset.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'electricity_cost_dataset.csv'"
          ]
        }
      ],
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, classification_report, confusion_matrix, roc_curve, auc\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"electricity_cost_dataset.csv\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace common NA representations\n",
        "df.replace(['?', 'NaN', 'nan', 'null', 'NULL', 'NA', 'na', ''], np.nan, inplace=True)\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Fill numeric NA by median, categorical by mode\n",
        "for col in df.select_dtypes(include=np.number).columns:\n",
        "    df[col].fillna(df[col].median(), inplace=True)\n",
        "for col in df.select_dtypes(include=object).columns:\n",
        "    df[col].fillna(df[col].mode()[0], inplace=True)\n",
        "\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "L3RUjCV-ZXpw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert Datetime columns if present\n",
        "for col in df.columns:\n",
        "    if 'date' in col.lower() or 'time' in col.lower():\n",
        "        df[col] = pd.to_datetime(df[col], errors='coerce')\n"
      ],
      "metadata": {
        "id": "ts97vW7jZZeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in df.select_dtypes(include=object).columns:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "VXB0CjzIZa7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "df_norm = df.copy()\n",
        "df_norm[df_norm.select_dtypes(include=np.number).columns] = scaler.fit_transform(df_norm.select_dtypes(include=np.number))\n",
        "\n",
        "stdscaler = StandardScaler()\n",
        "df_std = df.copy()\n",
        "df_std[df_std.select_dtypes(include=np.number).columns] = stdscaler.fit_transform(df_std.select_dtypes(include=np.number))\n",
        "\n",
        "print(\"Normalization and Standardization done.\")\n"
      ],
      "metadata": {
        "id": "F5_-35fwZcTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Before removing duplicates:\", df.shape)\n",
        "df = df.drop_duplicates()\n",
        "print(\"After removing duplicates:\", df.shape)\n"
      ],
      "metadata": {
        "id": "OqVYoVLaZdsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in df.select_dtypes(include=np.number).columns:\n",
        "    Q1 = df[col].quantile(0.25)\n",
        "    Q3 = df[col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower = Q1 - 1.5 * IQR\n",
        "    upper = Q3 + 1.5 * IQR\n",
        "    df[col] = np.where(df[col] < lower, lower, df[col])\n",
        "    df[col] = np.where(df[col] > upper, upper, df[col])\n",
        "\n",
        "print(\"Outliers treated.\")\n"
      ],
      "metadata": {
        "id": "9TiGO8evZfCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in df.columns:\n",
        "    df[col] = pd.to_numeric(df[col], errors='ignore')\n"
      ],
      "metadata": {
        "id": "vF-6_bQaZgoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_df = df.select_dtypes(include=np.number)\n",
        "selector = VarianceThreshold(threshold=0.01)\n",
        "numeric_selected = numeric_df.loc[:, selector.fit(numeric_df).get_support()]\n"
      ],
      "metadata": {
        "id": "TcpOm4ulZiUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr_matrix = numeric_selected.corr().abs()\n",
        "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
        "to_drop = [column for column in upper.columns if any(upper[column] > 0.9)]\n",
        "numeric_selected = numeric_selected.drop(columns=to_drop, errors='ignore')\n",
        "df_selected = pd.concat([numeric_selected, df.select_dtypes(exclude=np.number)], axis=1)\n",
        "\n",
        "print(\"Feature selection done. Final shape:\", df_selected.shape)\n"
      ],
      "metadata": {
        "id": "bUzxqBHxZkDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_selected.drop(columns=['electricity cost'])\n",
        "y = df_selected['electricity cost']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Training set shape:\", X_train.shape)\n",
        "print(\"Testing set shape:\", X_test.shape)\n"
      ],
      "metadata": {
        "id": "gQemKehXZlgW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LinearRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "print(\"Intercept:\", lr.intercept_)\n",
        "print(\"Number of coefficients:\", len(lr.coef_))\n",
        "\n",
        "y_pred = lr.predict(X_test)\n",
        "\n",
        "# Performance metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "n = X_test.shape[0]  # Number of samples\n",
        "p = X_test.shape[1]  # Number of features\n",
        "adj_r2 = 1 - (1-r2) * (n-1) / (n-p-1)  # Adjusted RÂ² formula\n",
        "\n",
        "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
        "print(f\"R Score: {r2:.4f}\")\n",
        "print(f\"Adjusted R Score: {adj_r2:.4f}\")\n",
        "\n",
        "# Create DataFrame for feature importance\n",
        "coef_df = pd.DataFrame({'Feature': X.columns, 'Coefficient': lr.coef_})\n",
        "coef_df = coef_df.sort_values(by='Coefficient', ascending=False).reset_index(drop=True)\n",
        "\n",
        "print(coef_df)\n"
      ],
      "metadata": {
        "id": "JUwVda09ZnNI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,6))\n",
        "plt.scatter(y_test, y_pred, alpha=0.5, color='blue', label=\"Predicted vs Actual\")\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2, label=\"Perfect Fit\")\n",
        "plt.xlabel(\"Actual electricity cost\")\n",
        "plt.ylabel(\"Predicted electricity cost\")\n",
        "plt.title(\"Linear Regression\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "cr_xbHjJZpT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare data for CV with encoding\n",
        "X_encoded = pd.get_dummies(X, drop_first=True)\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "cv_r2_scores = cross_val_score(lr, X_encoded, y, cv=kf, scoring='r2')\n",
        "cv_mse_scores = cross_val_score(lr, X_encoded, y, cv=kf, scoring='neg_mean_squared_error')\n",
        "cv_rmse_scores = np.sqrt(-cv_mse_scores)\n",
        "cv_mae_scores = cross_val_score(lr, X_encoded, y, cv=kf, scoring='neg_mean_absolute_error')\n",
        "\n",
        "print(\"Cross-validation R2 scores:\", cv_r2_scores)\n",
        "print(\"Mean R2:\", np.mean(cv_r2_scores))\n",
        "print(\"Standard Deviation of R2:\", np.std(cv_r2_scores))\n",
        "\n",
        "print(\"Cross-validation RMSE scores:\", cv_rmse_scores)\n",
        "print(\"Mean RMSE:\", np.mean(cv_rmse_scores))\n",
        "print(\"Cross-validation MAE scores:\", -cv_mae_scores)\n",
        "print(\"Mean MAE:\", -np.mean(cv_mae_scores))\n"
      ],
      "metadata": {
        "id": "Sl4UTCJOZrNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "plt.figure(figsize=(6, 4))  # Reduced figure size\n",
        "\n",
        "folds = range(1, len(cv_r2_scores) + 1)\n",
        "plt.plot(folds, cv_r2_scores, marker='o', linestyle='-', color='blue', label='R2 Score')\n",
        "plt.plot(folds, cv_rmse_scores, marker='s', linestyle='-', color='orange', label='RMSE')\n",
        "plt.plot(folds, -cv_mae_scores, marker='^', linestyle='-', color='green', label='MAE')\n",
        "\n",
        "plt.axhline(y=np.mean(cv_r2_scores), color='blue', linestyle='--', label=f\"Mean R2: {np.mean(cv_r2_scores):.4f}\")\n",
        "plt.axhline(y=np.mean(cv_rmse_scores), color='orange', linestyle='--', label=f\"Mean RMSE: {np.mean(cv_rmse_scores):.4f}\")\n",
        "plt.axhline(y=-np.mean(cv_mae_scores), color='green', linestyle='--', label=f\"Mean MAE: {np.mean(-cv_mae_scores):.4f}\")\n",
        "\n",
        "plt.xlabel(\"Fold Number\")\n",
        "plt.ylabel(\"Metric Value\")\n",
        "plt.title(\"Cross Validation Performance - Linear Regression (5 Folds)\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "oz6P0iL4bu2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"electricity_cost_dataset.csv\")\n",
        "\n",
        "X = df.drop(columns=['electricity cost'])\n",
        "y = df['electricity cost']\n",
        "\n",
        "\n",
        "cat_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "\n",
        "X_encoded = pd.get_dummies(X, columns=cat_cols, drop_first=True)\n",
        "\n",
        "print(\"Columns after encoding:\", X_encoded.columns)\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train multiple linear regression model\n",
        "lr = LinearRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = lr.predict(X_test)\n",
        "\n",
        "# Calculate performance metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = mse ** 0.5  # Manual RMSE calculation for compatibility\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Adjusted R-squared calculation\n",
        "n = len(y_test)  # Number of samples\n",
        "p = X_test.shape[1]  # Number of features\n",
        "adj_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
        "\n",
        "# Print metrics\n",
        "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
        "print(f\"R-squared (R2): {r2:.4f}\")\n",
        "print(f\"Adjusted R-squared: {adj_r2:.4f}\")\n",
        "\n",
        "# Coefficients as a DataFrame\n",
        "coefficients = pd.DataFrame({\n",
        "    'Feature': X_encoded.columns,\n",
        "    'Coefficient': lr.coef_\n",
        "})\n",
        "\n",
        "coefficients = coefficients.sort_values(by='Coefficient', ascending=False).reset_index(drop=True)\n",
        "print(coefficients)\n"
      ],
      "metadata": {
        "id": "rYJuO_AbaZXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "residuals = y_test - y_pred\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.histplot(residuals, bins=30, kde=True, color='purple')\n",
        "plt.xlabel(\"Residuals\")\n",
        "plt.title(\"Residuals Distribution\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.scatter(y_pred, residuals, alpha=0.5, color='green')\n",
        "plt.axhline(y=0, color='red', linestyle='--')\n",
        "plt.xlabel(\"Predicted Values\")\n",
        "plt.ylabel(\"Residuals\")\n",
        "plt.title(\"Residuals vs Predicted\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "EMMBAs60Zv-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['cost_category'] = pd.qcut(df['electricity cost'], q=3, labels=[\"Low\", \"Medium\", \"High\"])\n",
        "X_class = df.drop(columns=['electricity cost', 'cost_category'])\n",
        "y_class = df['cost_category']\n",
        "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(X_class, y_class, test_size=0.2, random_state=42, stratify=y_class)\n",
        "\n",
        "print(\"Training set:\", X_train_c.shape)\n",
        "print(\"Testing set:\", X_test_c.shape)\n"
      ],
      "metadata": {
        "id": "EMSQiNrwZzQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Example, assuming X_train_c and X_test_c are DataFrames\n",
        "X_train_c = pd.get_dummies(X_train_c)\n",
        "X_test_c = pd.get_dummies(X_test_c)\n",
        "\n",
        "# Align columns in case of any mismatch in categories between train and test\n",
        "X_train_c, X_test_c = X_train_c.align(X_test_c, join='left', axis=1, fill_value=0)\n",
        "\n",
        "logreg = LogisticRegression(max_iter=1000)\n",
        "logreg.fit(X_train_c, y_train_c)\n",
        "\n",
        "print(\"Training Accuracy:\", logreg.score(X_train_c, y_train_c))\n",
        "print(\"Testing Accuracy:\", logreg.score(X_test_c, y_test_c))\n"
      ],
      "metadata": {
        "id": "tSKjdFNxZ0-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_c = logreg.predict(X_test_c)\n",
        "\n",
        "print(\"Classification Report:\\n\", classification_report(y_test_c, y_pred_c))\n",
        "\n",
        "cm = confusion_matrix(y_test_c, y_pred_c)\n",
        "plt.figure(figsize=(6,5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[\"Low\", \"Medium\", \"High\"], yticklabels=[\"Low\", \"Medium\", \"High\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "0057InaDZ3y7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Scale classification features\n",
        "scaler = StandardScaler()\n",
        "X_train_c_scaled = scaler.fit_transform(X_train_c)\n",
        "X_test_c_scaled = scaler.transform(X_test_c)\n",
        "\n",
        "# One-vs-Rest logistic regression\n",
        "ovr = OneVsRestClassifier(LogisticRegression(max_iter=1000))\n",
        "y_train_bin = label_binarize(y_train_c, classes=[\"Low\", \"Medium\", \"High\"])\n",
        "y_test_bin = label_binarize(y_test_c, classes=[\"Low\", \"Medium\", \"High\"])\n",
        "\n",
        "ovr.fit(X_train_c_scaled, y_train_bin)\n",
        "y_score = ovr.decision_function(X_test_c_scaled)\n",
        "\n",
        "classes = [\"Low\", \"Medium\", \"High\"]\n",
        "plt.figure(figsize=(7,5))  # Reduced size for better display\n",
        "\n",
        "for i, cls in enumerate(classes):\n",
        "    fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.plot(fpr, tpr, label=f\"{cls} AUC {roc_auc:.2f}\")\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve - Logistic Regression\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "XkAGnpmiZ6Pb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***PCA***"
      ],
      "metadata": {
        "id": "kGQYjRbUEmJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv('electricity_cost_dataset.csv')\n",
        "\n",
        "# Take random subset, e.g. 200 rows\n",
        "subset = data.sample(n=200, random_state=42)\n",
        "\n",
        "# Select only numeric columns for PCA\n",
        "numeric_cols = subset.select_dtypes(include=[np.number]).columns\n",
        "numeric_data = subset[numeric_cols].copy()\n",
        "numeric_data = numeric_data.fillna(numeric_data.mean())\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaled_data = scaler.fit_transform(numeric_data)\n",
        "\n",
        "\n",
        "pca = PCA(n_components=3)\n",
        "pca_result = pca.fit_transform(scaled_data)\n",
        "pcadf = pd.DataFrame(pca_result, columns=['PC1', 'PC2', 'PC3'])\n",
        "\n",
        "# Get colors from 'structure type' (do not include in PCA)\n",
        "if 'structure type' in subset.columns:\n",
        "    type_col = subset['structure type'].astype(str)\n",
        "    main_types = type_col.value_counts().index[:2]\n",
        "    mask1 = (type_col == main_types[0])\n",
        "    mask2 = (type_col == main_types[1])\n",
        "    colors = np.where(mask1, 'royalblue', np.where(mask2, 'orangered', 'gray'))\n",
        "else:\n",
        "    colors = 'royalblue'\n",
        "\n",
        "# 3D PCA plot\n",
        "fig = plt.figure(figsize=(10,8))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.scatter(pcadf['PC1'], pcadf['PC2'], pcadf['PC3'], c=colors, s=60, alpha=0.8, edgecolor='k')\n",
        "ax.set_title('3D PCA Visualization (Subset)', fontsize=14)\n",
        "ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.1f}% Var)')\n",
        "ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.1f}% Var)')\n",
        "ax.set_zlabel(f'PC3 ({pca.explained_variance_ratio_[2]*100:.1f}% Var)')\n",
        "plt.legend(handles=[\n",
        "    plt.Line2D([], [], marker='o', color='w', label=main_types[0], markerfacecolor='royalblue', markersize=10, markeredgecolor='k'),\n",
        "    plt.Line2D([], [], marker='o', color='w', label=main_types[1], markerfacecolor='orangered', markersize=10, markeredgecolor='k')\n",
        "], title='Structure Type')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "OkwZXpfWEqHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **NAIVE BAYES**"
      ],
      "metadata": {
        "id": "FnXeaS14Hoda"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Load the dataset and select a random subset\n",
        "data = pd.read_csv('electricity_cost_dataset.csv')\n",
        "subset = data.sample(n=200, random_state=42)\n",
        "\n",
        "\n",
        "cat_cols = subset.select_dtypes(include=['object']).columns.tolist()\n",
        "le_dict = {}\n",
        "for col in cat_cols:\n",
        "    le = LabelEncoder()\n",
        "    subset[col] = le.fit_transform(subset[col].astype(str))\n",
        "    le_dict[col] = le\n",
        "\n",
        "# Features and target\n",
        "X = subset.drop('structure type', axis=1)\n",
        "y = subset['structure type']\n",
        "\n",
        "# Standardize numerical features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train NaÃ¯ve Bayes\n",
        "model = GaussianNB()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluation\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "zkEaxqLHICfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Step 2: Load Dataset\n",
        "data = pd.read_csv('/content/electricity_cost_dataset.csv')\n",
        "print(\"Dataset Loaded Successfully \")\n",
        "print(\"\\nFirst five rows of dataset:\")\n",
        "display(data.head())\n",
        "\n",
        "# Step 3: Dataset Information\n",
        "print(\"\\nDataset Information:\")\n",
        "print(data.info())\n",
        "\n",
        "# Step 4: Encode Categorical Columns\n",
        "label_encoders = {}\n",
        "for col in data.select_dtypes(include=['object']).columns:\n",
        "    le = LabelEncoder()\n",
        "    data[col] = le.fit_transform(data[col])\n",
        "    label_encoders[col] = le\n",
        "\n",
        "print(\"\\nCategorical columns encoded successfully \")\n",
        "display(data.head())\n",
        "\n",
        "# Step 5: Convert Target Variable to Categories\n",
        "# We'll convert electricity cost into 3 categories (Low, Medium, High)\n",
        "data['cost_category'] = pd.cut(\n",
        "    data['electricity cost'],\n",
        "    bins=3,\n",
        "    labels=['Low', 'Medium', 'High']\n",
        ")\n",
        "\n",
        "# Step 6: Define Feature Matrix (X) and Target Vector (y)\n",
        "X = data.drop(['electricity cost', 'cost_category'], axis=1)\n",
        "y = data['cost_category']\n",
        "\n",
        "# Step 7: Split Dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "print(\"\\nTraining and Testing Split Completed.\")\n",
        "print(f\"Training Data Shape: {X_train.shape}\")\n",
        "print(f\"Testing Data Shape: {X_test.shape}\")\n",
        "\n",
        "\n",
        "nb_model = GaussianNB()\n",
        "\n",
        "\n",
        "nb_model.fit(X_train, y_train)\n",
        "print(\"\\nNaÃ¯ve Bayes Model Trained Successfully \")\n",
        "\n",
        "# Step 10: Make Predictions\n",
        "y_pred = nb_model.predict(X_test)\n",
        "\n",
        "# Step 11: Evaluate Model Performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"\\nModel Evaluation Results:\")\n",
        "print(f\"Accuracy of NaÃ¯ve Bayes Classifier: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "# Classification Report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Step 12: Visualization of Confusion Matrix\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Greens')\n",
        "plt.title('Confusion Matrix - NaÃ¯ve Bayes Classifier')\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MLJBJnKRLEuW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **SVM**"
      ],
      "metadata": {
        "id": "HboLjyrDMyKl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "\n",
        "data = pd.read_csv('/content/electricity_cost_dataset.csv')\n",
        "for col in data.select_dtypes(include=['object']).columns:\n",
        "    data[col] = LabelEncoder().fit_transform(data[col])\n",
        "\n",
        "# Create categorical target\n",
        "data['cost_category'] = pd.cut(data['electricity cost'], bins=3, labels=['Low', 'Medium', 'High'])\n",
        "X = data.drop(['electricity cost', 'cost_category'], axis=1)\n",
        "y = data['cost_category']\n",
        "\n",
        "# Split & scale\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "scaler = StandardScaler()\n",
        "X_train, X_test = scaler.fit_transform(X_train), scaler.transform(X_test)\n",
        "\n",
        "# Train SVM\n",
        "svm = SVC(kernel='rbf', C=1.0, gamma='scale')\n",
        "svm.fit(X_train, y_train)\n",
        "y_pred = svm.predict(X_test)\n",
        "\n",
        "# Evaluation\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred)*100:.2f}%\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Purples')\n",
        "plt.title('SVM Confusion Matrix')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "d9r4OmFMM0LE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401\n",
        "\n",
        "# --- Load & prep ---\n",
        "df = pd.read_csv('/content/electricity_cost_dataset.csv')\n",
        "for c in df.select_dtypes('object'):\n",
        "    df[c] = LabelEncoder().fit_transform(df[c])\n",
        "df['cost_category'] = pd.cut(df['electricity cost'], 3, labels=['Low','Medium','High'])\n",
        "df = df.dropna(subset=['site area','water consumption','resident count','cost_category'])\n",
        "\n",
        "X = df[['site area','water consumption','resident count']].to_numpy()\n",
        "y = LabelEncoder().fit_transform(df['cost_category'])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test  = sc.transform(X_test)\n",
        "\n",
        "# --- Train SVM ---\n",
        "svm = SVC(kernel='rbf', gamma='scale')\n",
        "svm.fit(X_train, y_train)\n",
        "\n",
        "# --- Predict on TRAIN for coloring ---\n",
        "y_pred = svm.predict(X_train)\n",
        "\n",
        "# --- Stratified downsample to reduce clutter (NO slicing) ---\n",
        "def stratified_sample(X, y, per_class=600, seed=0):\n",
        "    rng = np.random.RandomState(seed)\n",
        "    keep_idx = []\n",
        "    for k in np.unique(y):\n",
        "        idx_k = np.where(y == k)[0]\n",
        "        n = min(per_class, len(idx_k))\n",
        "        keep_idx.append(rng.choice(idx_k, n, replace=False))\n",
        "    return np.concatenate(keep_idx)\n",
        "\n",
        "keep = stratified_sample(X_train, y_pred, per_class=600)  # tweak 300â€“800 as you like\n",
        "\n",
        "# --- Plot ---\n",
        "fig = plt.figure(figsize=(8,6))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "# smaller dots, lighter edges, a bit transparent\n",
        "ax.scatter(\n",
        "    X_train[keep,0], X_train[keep,1], X_train[keep,2],\n",
        "    c=y_pred[keep], cmap='viridis',\n",
        "    s=14, alpha=0.75, edgecolors='none', depthshade=True\n",
        ")\n",
        "\n",
        "ax.set_xlabel('Site Area (scaled)')\n",
        "ax.set_ylabel('Water Consumption (scaled)')\n",
        "ax.set_zlabel('Resident Count (scaled)')\n",
        "ax.set_title('3D SVM Electricity Cost')\n",
        "\n",
        "# nicer camera & aspect\n",
        "ax.view_init(elev=22, azim=45)\n",
        "rngs = X_train.max(axis=0) - X_train.min(axis=0)\n",
        "ax.set_box_aspect(rngs / rngs.max())\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Txo0GDQwM0fG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HIERARCHIAL** **CLUSTERING**\n"
      ],
      "metadata": {
        "id": "Mw3j43tTI4L2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np, pandas as pd, matplotlib.pyplot as plt, seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
        "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
        "from scipy.cluster.hierarchy import linkage, dendrogram\n",
        "\n",
        "# ---------- Load and Prepare ----------\n",
        "df = pd.read_csv('/content/electricity_cost_dataset.csv')\n",
        "for c in df.select_dtypes('object'):\n",
        "    df[c] = LabelEncoder().fit_transform(df[c])\n",
        "\n",
        "df['cost_category'] = pd.cut(df['electricity cost'], 3, labels=['Low','Medium','High'])\n",
        "df = df.dropna(subset=['site area','water consumption','resident count','cost_category'])\n",
        "\n",
        "X = df[['site area','water consumption','resident count']].to_numpy(dtype=float)\n",
        "sc = StandardScaler()\n",
        "Xs = sc.fit_transform(X)\n",
        "\n",
        "# ============================================================\n",
        "# ðŸ”¹ T10: Hierarchical Clustering\n",
        "# ============================================================\n",
        "\n",
        "Z = linkage(Xs, method='ward')\n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "dendrogram(Z, no_labels=True, color_threshold=None)\n",
        "plt.title('Hierarchical Clustering â€” Dendrogram (Ward)')\n",
        "plt.xlabel('Samples'); plt.ylabel('Distance')\n",
        "plt.tight_layout(); plt.show()\n",
        "\n",
        "hc = AgglomerativeClustering(n_clusters=3, linkage='ward')\n",
        "labels_hc = hc.fit_predict(Xs)\n",
        "\n",
        "# ---- 3D Plot for Hierarchical ----\n",
        "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401\n",
        "\n",
        "fig = plt.figure(figsize=(8, 6))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "# sample to avoid clutter\n",
        "idx = np.random.choice(len(Xs), size=min(1200, len(Xs)), replace=False)\n",
        "\n",
        "ax.scatter(Xs[idx,0], Xs[idx,1], Xs[idx,2],\n",
        "           c=labels_hc[idx], cmap='tab10', s=25, alpha=0.8, edgecolor='k', linewidth=0.2)\n",
        "\n",
        "ax.set_xlabel('Site Area (scaled)')\n",
        "ax.set_ylabel('Water Consumption (scaled)')\n",
        "ax.set_zlabel('Resident Count (scaled)')\n",
        "ax.set_title('T10: Hierarchical Clusters (k=3)')\n",
        "ax.view_init(elev=20, azim=40)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yoNqHEU5JIRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**K MEANS**"
      ],
      "metadata": {
        "id": "Rt9ZffDcJiFu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401\n",
        "\n",
        "# --- Load & preprocess ---\n",
        "df = pd.read_csv('/content/electricity_cost_dataset.csv')\n",
        "for c in df.select_dtypes('object'):\n",
        "    df[c] = LabelEncoder().fit_transform(df[c])\n",
        "\n",
        "df['cost_category'] = pd.cut(df['electricity cost'], 3, labels=['Low','Medium','High'])\n",
        "df = df.dropna(subset=['site area','water consumption','resident count','cost_category'])\n",
        "\n",
        "X = df[['site area','water consumption','resident count']].values\n",
        "sc = StandardScaler()\n",
        "X_scaled = sc.fit_transform(X)\n",
        "\n",
        "# --- K-Means ---\n",
        "kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
        "labels = kmeans.fit_predict(X_scaled)\n",
        "centers = kmeans.cluster_centers_\n",
        "\n",
        "# --- Random downsample to avoid clutter ---\n",
        "rng = np.random.RandomState(0)\n",
        "idx = rng.choice(len(X_scaled), size=min(1000, len(X_scaled)), replace=False)\n",
        "\n",
        "# --- 3D scatter plot ---\n",
        "fig = plt.figure(figsize=(9,7))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "# vivid colors per cluster\n",
        "colors = np.array(['#1f77b4', '#ff7f0e', '#2ca02c'])\n",
        "ax.scatter(X_scaled[idx,0], X_scaled[idx,1], X_scaled[idx,2],\n",
        "           c=colors[labels[idx]], s=45, alpha=0.78,\n",
        "           edgecolor='k', linewidth=0.25)\n",
        "\n",
        "# cluster centers (larger, visible)\n",
        "ax.scatter(centers[:,0], centers[:,1], centers[:,2],\n",
        "           c='red', s=400, marker='X', label='Cluster Centers',\n",
        "           edgecolor='white', linewidth=1.8)\n",
        "\n",
        "# --- Labels & appearance ---\n",
        "ax.set_xlabel('Site Area (scaled)', fontsize=11)\n",
        "ax.set_ylabel('Water Consumption (scaled)', fontsize=11)\n",
        "ax.set_zlabel('Resident Count (scaled)', fontsize=11)\n",
        "ax.set_title('T11: K-Means Clustering (k=3)', fontsize=14, pad=12)\n",
        "ax.legend(loc='upper left')\n",
        "\n",
        "# New viewing angle for better center visibility\n",
        "ax.view_init(elev=30, azim=120)   # <-- Adjust this angle for best view\n",
        "ax.grid(True, alpha=0.3)\n",
        "r = X_scaled.max(axis=0) - X_scaled.min(axis=0)\n",
        "ax.set_box_aspect(r / r.max())\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "crW7l8MXJlIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EVALUATION**\n"
      ],
      "metadata": {
        "id": "o7g3m95kJ0Uq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------- 4) T12: Cluster Evaluation ----------------\n",
        "def eval_scores(Xs, labels, name=''):\n",
        "    sil = silhouette_score(Xs, labels)\n",
        "    ch  = calinski_harabasz_score(Xs, labels)\n",
        "    db  = davies_bouldin_score(Xs, labels)\n",
        "    print(f'{name} -> Silhouette: {sil:.4f}  |  Calinski-Harabasz: {ch:.1f}  |  Davies-Bouldin: {db:.4f}')\n",
        "    return sil, ch, db\n",
        "\n",
        "print('T12: Cluster Quality (higher Silhouette & CH are better; lower DB is better)')\n",
        "eval_scores(Xs, labels_hc, 'Hierarchical (k=3)')\n",
        "eval_scores(Xs, labels_km, f'K-Means (k={k_opt})')"
      ],
      "metadata": {
        "id": "6vGjKtahJvF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**tutorials unit 5**"
      ],
      "metadata": {
        "id": "P1tPUA16LeZP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**decision trees**\n"
      ],
      "metadata": {
        "id": "Vid5QJ1NLk6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401\n",
        "\n",
        "# --- Load and preprocess ---\n",
        "df = pd.read_csv('/content/electricity_cost_dataset.csv')\n",
        "\n",
        "# Encode categorical columns\n",
        "for c in df.select_dtypes('object'):\n",
        "    df[c] = LabelEncoder().fit_transform(df[c])\n",
        "\n",
        "# Create target labels (Low, Medium, High)\n",
        "df['cost_category'] = pd.cut(df['electricity cost'], 3, labels=['Low','Medium','High'])\n",
        "df = df.dropna(subset=['site area','water consumption','resident count','cost_category'])\n",
        "\n",
        "# Features + target\n",
        "X = df[['site area','water consumption','resident count']].values\n",
        "y = LabelEncoder().fit_transform(df['cost_category'])\n",
        "\n",
        "# Split + scale\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "# --- Train Decision Tree ---\n",
        "dt = DecisionTreeClassifier(criterion='entropy', max_depth=4, random_state=42)\n",
        "dt.fit(X_train, y_train)\n",
        "y_pred = dt.predict(X_test)\n",
        "\n",
        "# --- Evaluation ---\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# --- 3D Scatter Plot (clear visualization) ---\n",
        "fig = plt.figure(figsize=(9,7))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "colors = np.array(['#1f77b4', '#ff7f0e', '#2ca02c'])\n",
        "ax.scatter(X_test[:,0], X_test[:,1], X_test[:,2],\n",
        "           c=colors[y_pred], s=50, alpha=0.8, edgecolor='k', linewidth=0.3)\n",
        "\n",
        "ax.set_xlabel('Site Area (scaled)', fontsize=11)\n",
        "ax.set_ylabel('Water Consumption (scaled)', fontsize=11)\n",
        "ax.set_zlabel('Resident Count (scaled)', fontsize=11)\n",
        "ax.set_title('T13: Decision Tree Classification Results', fontsize=14)\n",
        "ax.view_init(elev=25, azim=130)  # adjust angle for visibility\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# --- Clear Decision Tree Diagram ---\n",
        "plt.figure(figsize=(16,8))\n",
        "plot_tree(\n",
        "    dt,\n",
        "    filled=True,\n",
        "    rounded=True,\n",
        "    fontsize=10,\n",
        "    feature_names=['Site Area', 'Water Consumption', 'Resident Count'],\n",
        "    class_names=['Low','Medium','High']\n",
        ")\n",
        "plt.title('T13: Decision Tree Structure (max_depth=4)', fontsize=14)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "myYBp-NdLjJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# T14: Random Forest â€” clear 3D scatter + feature importances\n",
        "\n",
        "import pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# --- Load & preprocess ---\n",
        "df = pd.read_csv('/content/electricity_cost_dataset.csv')\n",
        "for c in df.select_dtypes('object'): df[c] = LabelEncoder().fit_transform(df[c])\n",
        "df['cost_category'] = pd.cut(df['electricity cost'], 3, labels=['Low','Medium','High'])\n",
        "df = df.dropna(subset=['site area','water consumption','resident count','cost_category'])\n",
        "\n",
        "FEATS = ['site area','water consumption','resident count']\n",
        "X = df[FEATS].to_numpy(float)\n",
        "y = LabelEncoder().fit_transform(df['cost_category'])\n",
        "\n",
        "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "sc = StandardScaler(); Xtr = sc.fit_transform(Xtr); Xte = sc.transform(Xte)\n",
        "\n",
        "# --- Train RF ---\n",
        "rf = RandomForestClassifier(\n",
        "    n_estimators=200, max_depth=6, min_samples_leaf=3,\n",
        "    random_state=42, n_jobs=-1, class_weight='balanced_subsample'\n",
        ").fit(Xtr, ytr)\n",
        "\n",
        "yp = rf.predict(Xte)\n",
        "proba = rf.predict_proba(Xte).max(axis=1)  # confidence for alpha sizing\n",
        "\n",
        "print(f\"Accuracy: {accuracy_score(yte, yp):.4f}\")\n",
        "print(classification_report(yte, yp, zero_division=0))\n",
        "\n",
        "# --- 3D Scatter (low clutter, confidence alpha) ---\n",
        "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401\n",
        "rng = np.random.RandomState(0)\n",
        "idx = rng.choice(len(Xte), size=min(1200, len(Xte)), replace=False)\n",
        "\n",
        "colors = np.array(['#1f77b4', '#ff7f0e', '#2ca02c'])\n",
        "alphas = 0.45 + 0.5*proba[idx]  # 0.45â€“0.95 transparency by confidence\n",
        "\n",
        "fig = plt.figure(figsize=(9,7))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.scatter(Xte[idx,0], Xte[idx,1], Xte[idx,2],\n",
        "           c=colors[yp[idx]], s=40, alpha=alphas, edgecolor='k', linewidth=0.25)\n",
        "ax.set_xlabel(f'{FEATS[0]} (scaled)'); ax.set_ylabel(f'{FEATS[1]} (scaled)'); ax.set_zlabel(f'{FEATS[2]} (scaled)')\n",
        "ax.set_title('T14: Random Forest â€” 3D Test Scatter (colored by predicted class)')\n",
        "ax.view_init(elev=25, azim=120)\n",
        "r = Xte.max(0) - Xte.min(0); ax.set_box_aspect(r/r.max()); plt.tight_layout(); plt.show()\n",
        "\n",
        "# --- Feature Importances (clear) ---\n",
        "imp = pd.Series(rf.feature_importances_, index=[f'{f} (scaled)' for f in FEATS]).sort_values()\n",
        "plt.figure(figsize=(6.2,3.8))\n",
        "imp.plot(kind='barh', color='#4444aa')\n",
        "plt.title('Random Forest â€” Feature Importances'); plt.xlabel('Importance'); plt.tight_layout(); plt.show()\n"
      ],
      "metadata": {
        "id": "u1h2A69GLvYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# T15: Artificial Neural Network (MLP) â€” clear 3D scatter + training loss\n",
        "\n",
        "import pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# --- Load & preprocess ---\n",
        "df = pd.read_csv('/content/electricity_cost_dataset.csv')\n",
        "for c in df.select_dtypes('object'): df[c] = LabelEncoder().fit_transform(df[c])\n",
        "df['cost_category'] = pd.cut(df['electricity cost'], 3, labels=['Low','Medium','High'])\n",
        "df = df.dropna(subset=['site area','water consumption','resident count','cost_category'])\n",
        "\n",
        "FEATS = ['site area','water consumption','resident count']\n",
        "X = df[FEATS].to_numpy(float)\n",
        "y = LabelEncoder().fit_transform(df['cost_category'])\n",
        "\n",
        "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "sc = StandardScaler(); Xtr = sc.fit_transform(Xtr); Xte = sc.transform(Xte)\n",
        "\n",
        "# --- Train MLP (stable, not too big) ---\n",
        "mlp = MLPClassifier(\n",
        "    hidden_layer_sizes=(32, 16),\n",
        "    activation='relu', solver='adam',\n",
        "    learning_rate_init=0.003, alpha=1e-4,\n",
        "    max_iter=500, random_state=42, early_stopping=True, n_iter_no_change=20, validation_fraction=0.15\n",
        ").fit(Xtr, ytr)\n",
        "\n",
        "yp = mlp.predict(Xte)\n",
        "proba = mlp.predict_proba(Xte).max(axis=1)\n",
        "\n",
        "print(f\"Accuracy: {accuracy_score(yte, yp):.4f}\")\n",
        "print(classification_report(yte, yp, zero_division=0))\n",
        "\n",
        "# --- 3D Scatter (confidence alpha) ---\n",
        "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401\n",
        "rng = np.random.RandomState(1)\n",
        "idx = rng.choice(len(Xte), size=min(1200, len(Xte)), replace=False)\n",
        "\n",
        "colors = np.array(['#1f77b4', '#ff7f0e', '#2ca02c'])\n",
        "alphas = 0.45 + 0.5*proba[idx]\n",
        "\n",
        "fig = plt.figure(figsize=(9,7))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.scatter(Xte[idx,0], Xte[idx,1], Xte[idx,2],\n",
        "           c=colors[yp[idx]], s=42, alpha=alphas, edgecolor='k', linewidth=0.25)\n",
        "ax.set_xlabel(f'{FEATS[0]} (scaled)'); ax.set_ylabel(f'{FEATS[1]} (scaled)'); ax.set_zlabel(f'{FEATS[2]} (scaled)')\n",
        "ax.set_title(' ANN (MLP) â€” 3D Test Scatter (colored by predicted class)')\n",
        "ax.view_init(elev=28, azim=135)\n",
        "r = Xte.max(0) - Xte.min(0); ax.set_box_aspect(r/r.max()); plt.tight_layout(); plt.show()\n",
        "\n",
        "# --- Training Loss Curve (for report clarity) ---\n",
        "plt.figure(figsize=(6.2,3.8))\n",
        "plt.plot(mlp.loss_curve_, lw=2)\n",
        "plt.title('ANN Training Loss'); plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.grid(alpha=0.3); plt.tight_layout(); plt.show()\n"
      ],
      "metadata": {
        "id": "wgqczmVRL1A1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}